{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Replace 'your_api_key_here' with your actual News API key\n",
        "api_key = '76bbc0f66fcd425fb060da85147bd998'\n",
        "\n",
        "# Define the endpoint URL\n",
        "url = 'https://newsapi.org/v2/top-headlines'\n",
        "\n",
        "# Specify the parameters\n",
        "params = {\n",
        "    'country': 'us',  # Get headlines from the United States\n",
        "    'apiKey': api_key\n",
        "}"
      ],
      "metadata": {
        "id": "jTyh7b2AubeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Qkzocse4s9FX",
        "outputId": "9768fd48-cbd9-41c2-cb14-493a2252ea0f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'NewsApiClient' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-924ab9aea893>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mDATA_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# pls dont steal my api key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnewsapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNewsApiClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'76bbc0f66fcd425fb060da85147bd998'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'NewsApiClient' is not defined"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "DATA_DIR = \"data/\"\n",
        "# pls dont steal my api key\n",
        "newsapi = api_key='76bbc0f66fcd425fb060da85147bd998'\n",
        "\n",
        "import json\n",
        "\n",
        "def check_news(company):\n",
        "    try:\n",
        "        with open(DATA_DIR + f'{company.lower()}.json') as json_file:\n",
        "            data = json.load(json_file)\n",
        "            print(\"News found\")\n",
        "            return True\n",
        "    except:\n",
        "        print(\"No news found\")\n",
        "        return False\n",
        "\n",
        "def get_news(company):\n",
        "    if (not check_news(company)):\n",
        "        articles = newsapi.get_everything(q=company,\n",
        "                                        language='en',\n",
        "                                        sort_by='relevancy',\n",
        "                                        )\n",
        "\n",
        "        with open(DATA_DIR + f'{company.lower()}.json', 'w') as outfile:\n",
        "            json.dump(articles, outfile)\n",
        "\n",
        "        return articles\n",
        "    else:\n",
        "        print(\"No news found\")\n",
        "        return None\n",
        "\n",
        "def get_sentiment(company):\n",
        "    get_news(company)\n",
        "    out = []\n",
        "\n",
        "    with open(DATA_DIR + f'{company.lower()}.json') as json_file:\n",
        "        data = json.load(json_file)\n",
        "\n",
        "        articles = data['articles']\n",
        "        for article in articles:\n",
        "            try:\n",
        "                out.append(article['title'] + \". \" + article['description'] + \". \" + article['content'])\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    for article in out:\n",
        "        out[out.index(article)] = sentiment.get_sentiment(article)\n",
        "\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Replace 'your_api_key_here' with your actual News API key\n",
        "api_key = '76bbc0f66fcd425fb060da85147bd998'\n",
        "\n",
        "# Define the endpoint URL\n",
        "url = 'https://newsapi.org/v2/top-headlines'\n",
        "\n",
        "# Specify the parameters\n",
        "params = {\n",
        "    'country': 'us',  # Get headlines from the United States\n",
        "    'apiKey': api_key\n",
        "}\n",
        "\n",
        "# Make the request\n",
        "response = requests.get(url, params=params)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Get JSON data\n",
        "    data = response.json()\n",
        "    # Print the headlines\n",
        "    for article in data['articles']:\n",
        "        print(article['title'])\n",
        "else:\n",
        "    print('Failed to retrieve news')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vz9LUaPuG3H",
        "outputId": "21e96e76-c402-4cfd-9525-e939a3c1d0b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Live updates: Trump hush money trial opening statements - CNN\n",
            "Rishi Sunak promises Rwanda deportation flights to start in 10-12 weeks - The Washington Post - The Washington Post\n",
            "Dallas Mavericks vs. Los Angeles Clippers Live Score and Stats - April 21, 2024 Gametracker - CBS Sports\n",
            "[Removed]\n",
            "S&P 500 aims to snap a rare 6-day drop. Here's what to expect next. - MarketWatch\n",
            "Tesla slashes Full Self-Driving price to $8,000 ahead of earnings report - The Verge\n",
            "Broncos unveil new uniforms with announcement of 'Mile High Collection' - DenverBroncos.com\n",
            "Police arrest dozens of pro-Palestine protesters at Yale - Axios\n",
            "Cheap, decades-old drug could be secret to longevity: scientists - New York Post \n",
            "Eric Edholm 2024 NFL mock draft 3.0: Six QBs; three trades; Eagles move up for CB - NFL.com\n",
            "[Removed]\n",
            "Supreme Court declines to hear Kari Lake voting machine lawsuit - The Hill\n",
            "Gold Price Forecast â€“ Gold Market Falls to Kick Off The Week - FX Empire\n",
            "Tales of Kenzera: Zau Review - IGN\n",
            "Floods swamp southern China, spark extreme weather fears - Reuters\n",
            "Supreme Court will take up the legal fight over ghost guns, firearms without serial numbers - The Associated Press\n",
            "Supreme Court will weigh banning homeless people from sleeping outside - The Associated Press\n",
            "[Removed]\n",
            "Steve Rosenberg: Russia defiant over new US aid to Ukraine - BBC.com\n",
            "Dominic West addresses 'deeply stressful' Lily James affair rumors - New York Post \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vrinda == true\n",
        "hater == true\n",
        "\n",
        "if vrinda == hater:\n",
        "  return \"Vrinda is a hater.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "cyHw-wuiQtLt",
        "outputId": "a89b8ce1-4970-4fb8-8dd5-71b4c5550b5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'vrinda' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5bb01a1ccb8b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvrinda\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mhater\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvrinda\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mhater\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"Vrinda is a hater.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vrinda' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "from textblob import TextBlob\n",
        "\n",
        "\n",
        "# Replace 'your_api_key_here' with your actual News API key\n",
        "api_key = '76bbc0f66fcd425fb060da85147bd998'\n",
        "DATA_DIR = './news_data/'  # Directory to store news data\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "def check_news(company):\n",
        "    \"\"\"Check if there is cached news for the company.\"\"\"\n",
        "    try:\n",
        "        with open(DATA_DIR + f'{company.lower()[:20]}.json', 'r') as json_file:\n",
        "            data = json.load(json_file)\n",
        "            print(\"News found\")\n",
        "            return True\n",
        "    except FileNotFoundError:\n",
        "        print(\"No news found\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def get_sentiment(text):\n",
        "    \"\"\"Return the sentiment polarity of the given text.\"\"\"\n",
        "    blob = TextBlob(text)\n",
        "    return blob.sentiment.polarity\n",
        "\n",
        "\n",
        "def get_news(company):\n",
        "    \"\"\"Fetch news from the API or local cache for the specified company.\"\"\"\n",
        "    if not check_news(company):\n",
        "        # Define the endpoint URL\n",
        "        url = 'https://newsapi.org/v2/everything'\n",
        "\n",
        "        # Specify the parameters for fetching news about the company\n",
        "        params = {\n",
        "            'q': company,\n",
        "            'language': 'en',\n",
        "            'sort_by': 'relevancy',\n",
        "            'apiKey': api_key\n",
        "        }\n",
        "\n",
        "        # Make the request\n",
        "        response = requests.get(url, params=params)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            articles = response.json()\n",
        "            # Save the fetched articles to a file\n",
        "            with open(DATA_DIR + f'{company.lower()[:20]}.json', 'w') as outfile:\n",
        "                json.dump(articles, outfile)\n",
        "            return articles\n",
        "        else:\n",
        "            print('Failed to retrieve news')\n",
        "            return None\n",
        "    else:\n",
        "        with open(DATA_DIR + f'{company.lower()[:20]}.json', 'r') as json_file:\n",
        "            return json.load(json_file)\n",
        "\n",
        "def get_sentiment(company):\n",
        "    \"\"\"Get sentiment analysis for news articles about the company.\"\"\"\n",
        "    articles_data = get_news(company)\n",
        "    if articles_data:\n",
        "        out = []\n",
        "        articles = articles_data['articles']\n",
        "        for article in articles:\n",
        "            try:\n",
        "                title = article['title'] if article['title'] else \"\"\n",
        "                description = article.get('description', '') if article.get('description', '') else \"\"\n",
        "                content = article.get('content', '') if article.get('content', '') else \"\"\n",
        "                full_content = f\"{title}. {description}. {content}\"\n",
        "                out.append(full_content)\n",
        "            except KeyError:\n",
        "                pass\n",
        "\n",
        "        # Analyze sentiment for each article\n",
        "        for index, article in enumerate(out):\n",
        "            sentiment_score = get_sentiment(article)\n",
        "            out[index] = (article, sentiment_score)\n",
        "\n",
        "        return out\n",
        "    else:\n",
        "        print(\"No news found\")\n",
        "        return []\n",
        "\n",
        "\n",
        "# Example of using the get_sentiment function\n",
        "company_name = \"Tesla\"\n",
        "sentiments = get_sentiment(company_name)\n",
        "print(sentiments)\n"
      ],
      "metadata": {
        "id": "9UvzjZTDvA3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Replace 'your_api_key_here' with your actual News API key\n",
        "api_key = '76bbc0f66fcd425fb060da85147bd998'\n",
        "DATA_DIR = './news_data/'  # Directory to store news data\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "def check_news(company):\n",
        "    \"\"\"Check if there is cached news for the company.\"\"\"\n",
        "    try:\n",
        "        with open(DATA_DIR + f'{company.lower()[:20]}.json', 'r') as json_file:\n",
        "            data = json.load(json_file)\n",
        "            print(\"News found\")\n",
        "            return True\n",
        "    except FileNotFoundError:\n",
        "        print(\"No news found\")\n",
        "        return False\n",
        "\n",
        "def get_sentiment(text):\n",
        "    \"\"\"Return the sentiment polarity rating (-1, 0, 1) of the given text.\"\"\"\n",
        "    blob = TextBlob(text)\n",
        "    polarity = blob.sentiment.polarity\n",
        "    if polarity > 0.1:  # Threshold for positive sentiment\n",
        "        return 1\n",
        "    elif polarity < -0.1:  # Threshold for negative sentiment\n",
        "        return -1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def get_news(company):\n",
        "    \"\"\"Fetch news from the API or local cache for the specified company.\"\"\"\n",
        "    if not check_news(company):\n",
        "        # Define the endpoint URL\n",
        "        url = 'https://newsapi.org/v2/everything'\n",
        "\n",
        "        # Specify the parameters for fetching news about the company\n",
        "        params = {\n",
        "            'q': company,\n",
        "            'language': 'en',\n",
        "            'sort_by': 'publishedAt',  # Sort by most recent\n",
        "            'pageSize': 100,  # Limit to 100 articles\n",
        "            'apiKey': api_key\n",
        "        }\n",
        "\n",
        "        # Make the request\n",
        "        response = requests.get(url, params=params)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            articles = response.json()\n",
        "            # Save the fetched articles to a file\n",
        "            with open(DATA_DIR + f'{company.lower()[:20]}.json', 'w') as outfile:\n",
        "                json.dump(articles, outfile)\n",
        "            return articles\n",
        "        else:\n",
        "            print('Failed to retrieve news')\n",
        "            return None\n",
        "    else:\n",
        "        with open(DATA_DIR + f'{company.lower()[:20]}.json', 'r') as json_file:\n",
        "            return json.load(json_file)\n",
        "\n",
        "def analyze_sentiments(company):\n",
        "    \"\"\"Get sentiment analysis for news article titles about the company.\"\"\"\n",
        "    articles_data = get_news(company)\n",
        "    if articles_data and 'articles' in articles_data:\n",
        "        out = []\n",
        "        for index, article in enumerate(articles_data['articles']):\n",
        "            title = article['title']\n",
        "            sentiment_score = get_sentiment(title)\n",
        "            out.append((index + 1, sentiment_score))  # Include article number and sentiment score\n",
        "        return out\n",
        "    else:\n",
        "        print(\"No news found\")\n",
        "        return []\n",
        "\n",
        "# Example of using the analyze_sentiments function\n",
        "company_name = \"Tesla\"\n",
        "sentiments = analyze_sentiments(company_name)\n",
        "for article_number, rating in sentiments:\n",
        "    print(f\"Article {article_number}: Rating {rating}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bUyHYb9xGdd",
        "outputId": "ded2e4a1-63fe-475a-fbb2-6b8d7762e0e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "News found\n",
            "Article 1: Rating 0\n",
            "Article 2: Rating 1\n",
            "Article 3: Rating -1\n",
            "Article 4: Rating 0\n",
            "Article 5: Rating 0\n",
            "Article 6: Rating 0\n",
            "Article 7: Rating -1\n",
            "Article 8: Rating 1\n",
            "Article 9: Rating 0\n",
            "Article 10: Rating 0\n",
            "Article 11: Rating 0\n",
            "Article 12: Rating 1\n",
            "Article 13: Rating -1\n",
            "Article 14: Rating 1\n",
            "Article 15: Rating 0\n",
            "Article 16: Rating -1\n",
            "Article 17: Rating -1\n",
            "Article 18: Rating 1\n",
            "Article 19: Rating 0\n",
            "Article 20: Rating 0\n",
            "Article 21: Rating 0\n",
            "Article 22: Rating 0\n",
            "Article 23: Rating 0\n",
            "Article 24: Rating 0\n",
            "Article 25: Rating 0\n",
            "Article 26: Rating 0\n",
            "Article 27: Rating 0\n",
            "Article 28: Rating 1\n",
            "Article 29: Rating 1\n",
            "Article 30: Rating 1\n",
            "Article 31: Rating 0\n",
            "Article 32: Rating 0\n",
            "Article 33: Rating -1\n",
            "Article 34: Rating 1\n",
            "Article 35: Rating 1\n",
            "Article 36: Rating 0\n",
            "Article 37: Rating 1\n",
            "Article 38: Rating 0\n",
            "Article 39: Rating 0\n",
            "Article 40: Rating 0\n",
            "Article 41: Rating 0\n",
            "Article 42: Rating 1\n",
            "Article 43: Rating 1\n",
            "Article 44: Rating 0\n",
            "Article 45: Rating 0\n",
            "Article 46: Rating 1\n",
            "Article 47: Rating -1\n",
            "Article 48: Rating 1\n",
            "Article 49: Rating 1\n",
            "Article 50: Rating 0\n",
            "Article 51: Rating 0\n",
            "Article 52: Rating 0\n",
            "Article 53: Rating 0\n",
            "Article 54: Rating 0\n",
            "Article 55: Rating 0\n",
            "Article 56: Rating 0\n",
            "Article 57: Rating 0\n",
            "Article 58: Rating 0\n",
            "Article 59: Rating -1\n",
            "Article 60: Rating 1\n",
            "Article 61: Rating 0\n",
            "Article 62: Rating 1\n",
            "Article 63: Rating 1\n",
            "Article 64: Rating 0\n",
            "Article 65: Rating 0\n",
            "Article 66: Rating 0\n",
            "Article 67: Rating 0\n",
            "Article 68: Rating -1\n",
            "Article 69: Rating 0\n",
            "Article 70: Rating 0\n",
            "Article 71: Rating 0\n",
            "Article 72: Rating 0\n",
            "Article 73: Rating 1\n",
            "Article 74: Rating 0\n",
            "Article 75: Rating 0\n",
            "Article 76: Rating 0\n",
            "Article 77: Rating 0\n",
            "Article 78: Rating 0\n",
            "Article 79: Rating 1\n",
            "Article 80: Rating 0\n",
            "Article 81: Rating 1\n",
            "Article 82: Rating 0\n",
            "Article 83: Rating 0\n",
            "Article 84: Rating 0\n",
            "Article 85: Rating -1\n",
            "Article 86: Rating -1\n",
            "Article 87: Rating 0\n",
            "Article 88: Rating 0\n",
            "Article 89: Rating 0\n",
            "Article 90: Rating 1\n",
            "Article 91: Rating 0\n",
            "Article 92: Rating 0\n",
            "Article 93: Rating 1\n",
            "Article 94: Rating 0\n",
            "Article 95: Rating 0\n",
            "Article 96: Rating 1\n",
            "Article 97: Rating 0\n",
            "Article 98: Rating 1\n",
            "Article 99: Rating 1\n",
            "Article 100: Rating 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Replace 'your_api_key_here' with your actual News API key\n",
        "api_key = '76bbc0f66fcd425fb060da85147bd998'\n",
        "DATA_DIR = './news_data/'  # Directory to store news data\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "def check_news(company):\n",
        "    \"\"\"Check if there is cached news for the company.\"\"\"\n",
        "    try:\n",
        "        with open(DATA_DIR + f'{company.lower()[:20]}.json', 'r') as json_file:\n",
        "            data = json.load(json_file)\n",
        "            print(\"News found\")\n",
        "            return True\n",
        "    except FileNotFoundError:\n",
        "        print(\"No news found\")\n",
        "        return False\n",
        "\n",
        "def get_sentiment_and_confidence(text):\n",
        "    \"\"\"Return the sentiment polarity rating (-1, 0, 1) and confidence of the given text.\"\"\"\n",
        "    blob = TextBlob(text)\n",
        "    polarity = blob.sentiment.polarity\n",
        "    confidence = abs(polarity)  # Absolute value of polarity as confidence\n",
        "    if polarity > 0.1:  # Threshold for positive sentiment\n",
        "        return 1, confidence\n",
        "    elif polarity < -0.1:  # Threshold for negative sentiment\n",
        "        return -1, confidence\n",
        "    else:\n",
        "        return 0, confidence\n",
        "\n",
        "def get_news(company):\n",
        "    \"\"\"Fetch news from the API or local cache for the specified company.\"\"\"\n",
        "    if not check_news(company):\n",
        "        # Define the endpoint URL\n",
        "        url = 'https://newsapi.org/v2/everything'\n",
        "\n",
        "        # Specify the parameters for fetching news about the company\n",
        "        params = {\n",
        "            'q': company,\n",
        "            'language': 'en',\n",
        "            'sort_by': 'publishedAt',  # Sort by most recent\n",
        "            'pageSize': 100,  # Limit to 100 articles\n",
        "            'apiKey': api_key\n",
        "        }\n",
        "\n",
        "        # Make the request\n",
        "        response = requests.get(url, params=params)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            articles = response.json()\n",
        "            # Save the fetched articles to a file\n",
        "            with open(DATA_DIR + f'{company.lower()[:20]}.json', 'w') as outfile:\n",
        "                json.dump(articles, outfile)\n",
        "            return articles\n",
        "        else:\n",
        "            print('Failed to retrieve news')\n",
        "            return None\n",
        "    else:\n",
        "        with open(DATA_DIR + f'{company.lower()[:20]}.json', 'r') as json_file:\n",
        "            return json.load(json_file)\n",
        "\n",
        "def analyze_sentiments(company):\n",
        "    \"\"\"Get sentiment analysis for news article titles about the company.\"\"\"\n",
        "    articles_data = get_news(company)\n",
        "    if articles_data and 'articles' in articles_data:\n",
        "        total_confidence = 0\n",
        "        weighted_sentiment_sum = 0\n",
        "        for article in articles_data['articles']:\n",
        "            title = article['title']\n",
        "            sentiment, confidence = get_sentiment_and_confidence(title)\n",
        "            weighted_sentiment_sum += sentiment * confidence\n",
        "            total_confidence += confidence\n",
        "\n",
        "        overall_sentiment_score = weighted_sentiment_sum / total_confidence if total_confidence != 0 else 0\n",
        "        return overall_sentiment_score\n",
        "    else:\n",
        "        print(\"No news found\")\n",
        "        return 0\n",
        "\n",
        "# Example of using the analyze_sentiments function\n",
        "company_name = \"Tesla\"\n",
        "overall_sentiment = analyze_sentiments(company_name)\n",
        "print(f\"Overall Sentiment Score for {company_name}: {overall_sentiment:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PQPpc4sxySh",
        "outputId": "0d0750e1-d6cf-407e-fc2e-321e8b3ebc35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "News found\n",
            "Overall Sentiment Score for Tesla: 0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from textblob import TextBlob\n",
        "\n",
        "def get_news():\n",
        "    file_path = 'aapl_news.csv'\n",
        "    try:\n",
        "        with open(file_path, mode='r', newline='', encoding='utf-8') as file:\n",
        "            csv_reader = csv.DictReader(file)\n",
        "            articles = {'articles': [row for row in csv_reader]}\n",
        "            return articles\n",
        "    except FileNotFoundError:\n",
        "        print(\"News file not found.\")\n",
        "        return None\n",
        "\n",
        "def get_sentiment_and_confidence(text):\n",
        "    \"\"\"Return the sentiment polarity rating (-1, 0, 1) and confidence of the given text.\"\"\"\n",
        "    blob = TextBlob(text)\n",
        "    polarity = blob.sentiment.polarity\n",
        "    confidence = abs(polarity)  # Absolute value of polarity as confidence\n",
        "    if polarity > 0.1:  # Threshold for positive sentiment\n",
        "        return 1, confidence\n",
        "    elif polarity < -0.1:  # Threshold for negative sentiment\n",
        "        return -1, confidence\n",
        "    else:\n",
        "        return 0, confidence\n",
        "\n",
        "def analyze_sentiments():\n",
        "    articles_data = get_news()\n",
        "    if articles_data and 'articles' in articles_data:\n",
        "        total_confidence = 0\n",
        "        weighted_sentiment_sum = 0\n",
        "        for article in articles_data['articles']:\n",
        "            title = article['title']\n",
        "            sentiment, confidence = get_sentiment_and_confidence(title)\n",
        "            weighted_sentiment_sum += sentiment * confidence\n",
        "            total_confidence += confidence\n",
        "        overall_sentiment_score = weighted_sentiment_sum / total_confidence if total_confidence != 0 else 0\n",
        "        return overall_sentiment_score\n",
        "    else:\n",
        "        print(\"No news found\")\n",
        "        return 0\n",
        "\n",
        "overall_sentiment = analyze_sentiments()\n",
        "print(f\"Overall Sentiment Score for Apple: {overall_sentiment:.2f}\")\n"
      ],
      "metadata": {
        "id": "_WobGL9j3QPN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "051835ba-2ead-45f3-9422-2d40dd72635e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Sentiment Score for Apple: 0.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from textblob import TextBlob\n",
        "from collections import defaultdict\n",
        "\n",
        "def get_news():\n",
        "    file_path = 'aapl_news.csv'\n",
        "    try:\n",
        "        with open(file_path, mode='r', newline='', encoding='utf-8') as file:\n",
        "            csv_reader = csv.DictReader(file)\n",
        "            articles = [row for row in csv_reader]\n",
        "            return articles\n",
        "    except FileNotFoundError:\n",
        "        print(\"News file not found.\")\n",
        "        return None\n",
        "\n",
        "def get_sentiment_and_confidence(text):\n",
        "    \"\"\"Return the sentiment polarity rating (-1, 0, 1) and confidence of the given text.\"\"\"\n",
        "    blob = TextBlob(text)\n",
        "    polarity = blob.sentiment.polarity\n",
        "    confidence = abs(polarity)  # Absolute value of polarity as confidence\n",
        "    if polarity > 0.1:\n",
        "        return 1, confidence\n",
        "    elif polarity < -0.1:\n",
        "        return -1, confidence\n",
        "    else:\n",
        "        return 0, confidence\n",
        "\n",
        "def analyze_sentiments():\n",
        "    articles_data = get_news()\n",
        "    if articles_data:\n",
        "        sentiment_by_date = defaultdict(lambda: {'total_confidence': 0, 'weighted_sentiment_sum': 0})\n",
        "        for article in articles_data:\n",
        "            title = article['title']\n",
        "            date = article['date']  # Assuming there's a 'date' column in your CSV\n",
        "            sentiment, confidence = get_sentiment_and_confidence(title)\n",
        "            sentiment_by_date[date]['weighted_sentiment_sum'] += sentiment * confidence\n",
        "            sentiment_by_date[date]['total_confidence'] += confidence\n",
        "\n",
        "        sentiment_scores = {}\n",
        "        for date, data in sentiment_by_date.items():\n",
        "            if data['total_confidence'] != 0:\n",
        "                sentiment_scores[date] = data['weighted_sentiment_sum'] / data['total_confidence']\n",
        "            else:\n",
        "                sentiment_scores[date] = 0  # Handle case with no data or zero confidence\n",
        "\n",
        "        return sentiment_scores\n",
        "    else:\n",
        "        print(\"No news found\")\n",
        "        return {}\n",
        "\n",
        "overall_sentiment_scores = analyze_sentiments()\n",
        "for date, score in overall_sentiment_scores.items():\n",
        "    print(f\"Sentiment Score for {date}: {score:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaZAli30sSqF",
        "outputId": "1f42a012-e1db-4463-baee-80ba5429fada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment Score for 2020-06-10 11:33:00-04:00: 1.00\n",
            "Sentiment Score for 2020-06-10 08:14:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-10 07:53:00-04:00: 1.00\n",
            "Sentiment Score for 2020-06-10 07:19:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-10 06:27:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-10 00:52:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-09 15:14:00-04:00: 1.00\n",
            "Sentiment Score for 2020-06-09 13:58:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-09 12:41:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-09 11:11:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-09 10:59:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-09 10:31:00-04:00: 1.00\n",
            "Sentiment Score for 2020-06-09 03:51:00-04:00: 1.00\n",
            "Sentiment Score for 2020-06-09 00:25:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-08 14:16:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-08 09:35:00-04:00: 1.00\n",
            "Sentiment Score for 2020-06-08 04:34:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-07 17:03:00-04:00: 1.00\n",
            "Sentiment Score for 2020-06-06 18:36:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-05 17:19:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-05 12:24:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-05 10:43:00-04:00: 1.00\n",
            "Sentiment Score for 2020-06-05 10:30:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-05 10:08:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-05 08:43:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-05 08:27:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-05 07:02:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-05 05:42:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-05 00:07:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-04 13:47:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-04 10:12:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-04 01:01:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-03 15:47:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-03 11:00:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-03 10:47:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-03 10:00:00-04:00: 1.00\n",
            "Sentiment Score for 2020-06-03 08:31:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-03 06:09:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-03 04:57:00-04:00: 1.00\n",
            "Sentiment Score for 2020-06-02 11:37:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-02 07:44:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-02 07:41:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-02 06:12:00-04:00: -1.00\n",
            "Sentiment Score for 2020-06-02 06:03:00-04:00: -1.00\n",
            "Sentiment Score for 2020-06-02 04:18:00-04:00: 1.00\n",
            "Sentiment Score for 2020-06-02 00:35:00-04:00: 0.00\n",
            "Sentiment Score for 2020-06-01 10:14:00-04:00: -1.00\n",
            "Sentiment Score for 2020-06-01 08:20:00-04:00: 1.00\n",
            "Sentiment Score for 2020-06-01 06:53:00-04:00: -1.00\n",
            "Sentiment Score for 2020-06-01 05:39:00-04:00: 1.00\n",
            "Sentiment Score for 2020-06-01 03:55:00-04:00: 1.00\n",
            "Sentiment Score for 2020-06-01 00:34:00-04:00: -1.00\n",
            "Sentiment Score for 2020-05-31 18:19:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-29 10:09:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-28 10:45:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-28 09:45:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-28 09:13:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-28 08:14:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-27 19:06:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-27 16:31:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-27 12:48:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-27 11:23:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-27 10:29:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-27 09:24:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-27 09:19:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-27 07:37:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-27 06:30:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-27 05:27:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-26 16:35:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-26 13:23:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-26 07:15:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-25 07:32:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-22 11:44:00-04:00: -1.00\n",
            "Sentiment Score for 2020-05-21 15:06:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-21 15:02:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-21 13:25:00-04:00: -1.00\n",
            "Sentiment Score for 2020-05-21 12:44:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-21 07:05:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-21 00:55:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-20 13:02:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-20 06:53:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-20 06:43:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-20 05:42:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-20 05:31:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-20 03:28:00-04:00: -1.00\n",
            "Sentiment Score for 2020-05-19 16:46:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-19 10:08:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-19 09:15:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-19 08:15:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-18 13:45:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-18 01:26:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-17 11:00:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-16 17:12:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-15 16:25:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-15 11:40:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-15 10:22:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-15 09:41:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-15 08:25:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-15 05:53:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-15 03:44:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-15 00:57:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-15 00:00:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-14 17:00:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-14 13:54:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-14 12:33:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-14 09:54:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-13 15:15:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-13 13:45:00-04:00: -1.00\n",
            "Sentiment Score for 2020-05-13 06:49:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-12 18:07:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-12 16:11:00-04:00: -1.00\n",
            "Sentiment Score for 2020-05-12 13:49:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-12 10:58:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-12 08:43:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-12 08:32:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-12 06:43:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-12 04:57:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-11 11:27:00-04:00: -1.00\n",
            "Sentiment Score for 2020-05-11 06:25:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-09 15:06:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-08 15:29:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-08 15:02:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-08 10:58:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-08 10:23:00-04:00: -1.00\n",
            "Sentiment Score for 2020-05-08 04:25:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-06 17:15:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-06 10:19:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-06 09:47:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-06 09:23:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-06 05:22:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-05 16:00:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-05 15:35:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-05 12:00:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-05 09:49:00-04:00: -1.00\n",
            "Sentiment Score for 2020-05-05 08:46:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-05 06:10:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-04 22:30:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-04 16:33:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-04 16:15:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-04 15:53:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-04 09:55:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-04 08:32:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-04 08:16:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-02 09:40:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-01 17:12:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-01 14:36:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-01 11:21:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-01 11:07:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-01 10:45:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-01 10:44:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-01 10:40:00-04:00: -1.00\n",
            "Sentiment Score for 2020-05-01 10:35:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-01 10:33:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-01 10:31:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-01 09:56:00-04:00: -1.00\n",
            "Sentiment Score for 2020-05-01 09:13:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-01 09:04:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-01 08:17:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-01 08:08:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-01 07:41:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-01 07:31:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-01 07:15:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-01 06:48:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-01 06:45:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-01 06:38:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-01 05:55:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-01 05:23:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-01 04:59:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-01 04:15:00-04:00: 0.00\n",
            "Sentiment Score for 2020-05-01 01:09:00-04:00: 1.00\n",
            "Sentiment Score for 2020-05-01 00:54:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-30 17:53:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-30 17:49:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-30 17:48:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-30 17:47:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-30 17:42:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-30 17:40:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-30 17:38:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-30 17:35:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-30 17:32:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-30 17:27:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-30 17:25:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-30 17:12:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-30 17:11:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-30 17:08:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-30 17:06:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-30 17:05:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-30 16:40:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-30 16:34:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-30 16:33:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-30 16:32:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-30 16:31:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-30 16:30:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-30 16:20:00-04:00: -1.00\n",
            "Sentiment Score for 2020-04-30 10:42:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-30 09:54:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-30 09:10:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-30 08:20:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-30 06:01:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-30 04:59:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-30 04:16:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-29 10:53:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-29 10:01:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-29 06:47:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-29 05:04:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-28 17:31:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-28 10:06:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-27 17:17:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-27 16:05:00-04:00: -1.00\n",
            "Sentiment Score for 2020-04-27 14:35:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-27 13:38:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-27 12:10:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-27 12:09:00-04:00: -1.00\n",
            "Sentiment Score for 2020-04-27 11:38:00-04:00: -1.00\n",
            "Sentiment Score for 2020-04-27 11:22:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-27 10:33:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-27 09:44:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-27 08:53:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-27 08:52:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-27 08:06:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-27 07:36:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-27 05:28:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-26 23:07:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-25 15:20:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-24 13:48:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-24 12:31:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-24 08:12:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-24 07:05:00-04:00: -1.00\n",
            "Sentiment Score for 2020-04-24 06:41:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-24 05:26:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-23 14:36:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-23 11:19:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-23 10:28:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-23 08:29:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-23 06:14:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-23 05:25:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-22 19:22:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-22 14:58:00-04:00: -1.00\n",
            "Sentiment Score for 2020-04-22 09:46:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-22 07:40:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-21 14:33:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-21 10:52:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-21 10:02:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-21 08:27:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-21 05:47:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-21 05:42:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-20 21:00:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-20 10:16:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-20 09:43:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-19 12:56:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-18 16:44:00-04:00: -1.00\n",
            "Sentiment Score for 2020-04-18 16:12:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-17 15:59:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-17 12:17:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-17 09:46:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-17 09:39:00-04:00: -1.00\n",
            "Sentiment Score for 2020-04-17 09:31:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-17 09:20:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-17 08:14:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-17 05:54:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-17 05:33:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-17 03:07:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-16 19:30:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-16 18:11:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-16 16:07:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-16 13:51:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-16 11:14:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-16 10:03:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-16 09:49:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-16 06:41:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-15 20:10:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-15 15:14:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-15 13:30:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-15 13:09:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-15 12:03:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-15 11:02:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-14 12:32:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-14 10:40:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-14 09:56:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-14 08:03:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-14 05:22:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-13 16:01:00-04:00: -1.00\n",
            "Sentiment Score for 2020-04-13 12:26:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-13 12:09:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-13 08:27:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-13 06:37:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-13 06:08:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-12 22:58:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-11 14:10:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-09 15:39:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-09 12:04:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-09 10:52:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-09 10:42:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-09 10:38:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-08 22:16:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-08 15:32:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-08 13:52:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-08 12:03:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-08 11:52:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-08 10:13:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-08 08:22:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-08 06:45:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-08 06:22:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-08 06:20:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-07 07:45:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-07 05:22:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-06 22:28:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-06 13:54:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-06 12:23:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-06 09:59:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-06 08:13:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-05 22:46:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-04 17:10:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-04 14:25:00-04:00: 1.00\n",
            "Sentiment Score for 2020-04-03 12:45:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-03 09:49:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-03 08:47:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-03 05:36:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-03 05:16:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-02 06:57:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-02 05:59:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-02 05:30:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-01 15:18:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-01 13:44:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-01 10:38:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-01 09:52:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-01 07:33:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-01 05:55:00-04:00: 0.00\n",
            "Sentiment Score for 2020-04-01 04:50:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-31 22:36:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-31 15:16:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-31 13:44:00-04:00: -1.00\n",
            "Sentiment Score for 2020-03-31 09:16:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-31 05:32:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-30 15:56:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-30 10:23:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-30 09:20:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-30 09:08:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-29 12:30:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-28 19:22:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-27 15:46:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-27 15:45:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-27 15:44:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-27 15:15:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-27 12:17:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-27 09:59:00-04:00: -1.00\n",
            "Sentiment Score for 2020-03-27 09:48:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-27 09:27:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-27 06:45:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-27 05:14:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-27 05:01:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-27 01:21:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-26 14:42:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-26 00:50:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-25 22:11:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-25 15:44:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-25 15:24:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-25 12:52:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-25 10:25:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-25 09:49:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-25 09:42:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-25 06:11:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-25 05:21:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-25 05:01:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-25 04:02:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-24 15:17:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-24 14:43:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-24 13:06:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-24 12:50:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-24 09:56:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-24 09:10:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-24 07:12:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-23 22:29:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-23 12:27:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-23 11:14:00-04:00: -1.00\n",
            "Sentiment Score for 2020-03-23 10:12:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-23 08:21:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-23 07:40:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-23 05:33:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-23 03:37:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-21 16:11:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-20 08:31:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-20 06:15:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-19 10:12:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-19 08:50:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-18 11:26:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-18 09:53:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-18 08:48:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-18 08:01:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-17 11:48:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-17 11:46:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-17 11:42:00-04:00: 0.56\n",
            "Sentiment Score for 2020-03-17 10:23:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-17 09:06:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-17 08:47:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-17 06:49:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-17 06:43:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-17 06:13:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-17 01:42:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-17 01:10:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-16 23:55:00-04:00: -1.00\n",
            "Sentiment Score for 2020-03-16 22:16:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-16 14:12:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-16 12:00:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-16 11:41:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-16 10:01:00-04:00: -1.00\n",
            "Sentiment Score for 2020-03-16 07:24:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-16 05:42:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-16 05:03:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-16 04:50:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-15 22:54:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-15 22:16:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-15 09:45:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-15 09:21:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-14 12:58:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-14 11:02:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-13 13:29:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-13 12:38:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-13 12:36:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-13 12:01:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-13 10:12:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-13 09:57:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-13 09:54:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-13 09:07:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-13 08:26:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-13 05:36:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-13 05:33:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-12 17:15:00-04:00: -1.00\n",
            "Sentiment Score for 2020-03-12 12:40:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-12 12:02:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-12 10:35:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-12 09:02:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-11 22:01:00-04:00: -1.00\n",
            "Sentiment Score for 2020-03-11 14:20:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-11 14:10:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-11 12:44:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-11 11:51:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-11 10:44:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-11 10:37:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-11 09:58:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-11 09:50:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-11 09:02:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-11 07:51:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-11 07:17:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-11 03:45:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-10 13:59:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-10 11:16:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-10 10:34:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-10 10:27:00-04:00: 1.00\n",
            "Sentiment Score for 2020-03-10 09:42:00-04:00: -1.00\n",
            "Sentiment Score for 2020-03-10 07:11:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-10 07:06:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-10 05:57:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-09 17:09:00-04:00: -1.00\n",
            "Sentiment Score for 2020-03-09 13:57:00-04:00: 0.00\n",
            "Sentiment Score for 2020-03-09 12:00:00-04:00: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def perform_run(data, chart_title, epochs=30):\n",
        "  # Loading data\n",
        "  data = pd.read_csv(f\"raw_{data}.csv\", index_col=0, parse_dates=True)\n",
        "\n",
        "  # Splitting data for training and testing\n",
        "  test_period_start = '2019-02-01'\n",
        "  test_period_end = '2019-04-29'\n",
        "\n",
        "  test_data = data.loc[test_period_start:test_period_end]\n",
        "\n",
        "  train_data = data[:'2019-02-01']\n",
        "\n",
        "  # Normalize the data\n",
        "  data_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "  data_norm = pd.DataFrame(data_scaler.fit_transform(data), index=data.index, columns=data.columns)\n",
        "\n",
        "  close_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "  train_close_scaled = close_scaler.fit_transform(train_data[['Close']])\n",
        "\n",
        "  test_close_scaled = close_scaler.transform(test_data[['Close']])\n",
        "\n",
        "  # Create sequences\n",
        "  seq_length = 5\n",
        "  def create_sequences(df, seq_length):\n",
        "      sequences = []\n",
        "      for i in range(len(df) - seq_length):\n",
        "          sequences.append(df.iloc[i:i + seq_length])\n",
        "      return sequences\n",
        "\n",
        "  data_seq = create_sequences(data_norm, seq_length)\n",
        "  data_seq_reshaped = np.array([sequence.values for sequence in data_seq])\n",
        "\n",
        "  # Building the LSTM model\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(units=50, return_sequences=True, input_shape=(seq_length, 6)))\n",
        "  model.add(LSTM(units=50))\n",
        "  model.add(Dense(units=1))\n",
        "\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "  data_target = data_norm['Close'].shift(-1)\n",
        "  data_target = data_target[:-seq_length]\n",
        "  data_target = data_target[0:data_seq_reshaped.shape[0]]\n",
        "\n",
        "  # Configure the early stopping\n",
        "  early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        min_delta=0.0001,\n",
        "        patience=5,\n",
        "        verbose=1,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "  # Fitting the model\n",
        "  history = model.fit(data_seq_reshaped, data_target, epochs=epochs, batch_size=32, validation_split=.1, callbacks=[early_stopping])\n",
        "\n",
        "  test_data_norm = pd.DataFrame(data_scaler.transform(test_data), index=test_data.index, columns=test_data.columns)\n",
        "\n",
        "  test_data_seq = create_sequences(test_data_norm, seq_length)\n",
        "  test_data_seq_reshaped = np.array([sequence.values for sequence in test_data_seq])\n",
        "\n",
        "  test_data_target = test_data_norm['Close'].iloc[seq_length:].values\n",
        "\n",
        "  test_predictions = model.predict(test_data_seq_reshaped)\n",
        "  test_predictions = test_predictions.flatten()\n",
        "\n",
        "  # Analyzing error\n",
        "  rmse = sqrt(mean_squared_error(test_data_target, test_predictions))\n",
        "  print(\"Test RMSE: \", rmse)\n",
        "\n",
        "  test_predictions_reshaped = test_predictions.reshape(-1, 1)\n",
        "  test_actual_predictions = close_scaler.inverse_transform(test_predictions_reshaped).flatten()\n",
        "\n",
        "  dates = test_data.index\n",
        "\n",
        "  actual_prices = test_data['Close']\n",
        "  prediction_dates = dates[seq_length:]\n",
        "\n",
        "  plt.figure(figsize=(10, 5))\n",
        "\n",
        "  plt.plot(dates, actual_prices, label='Actual Prices', marker='o')\n",
        "  plt.plot(prediction_dates, test_actual_predictions, label='Predicted Prices', marker='x')\n",
        "\n",
        "  plt.title(f\"Stock Price Prediction for {chart_title}\")\n",
        "  plt.xlabel('Date')\n",
        "  plt.ylabel('Stock Price ($)')\n",
        "\n",
        "  plt.legend()\n",
        "\n",
        "  plt.grid(True)\n",
        "\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "9F09miiMtFHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from textblob import TextBlob\n",
        "from collections import defaultdict\n",
        "\n",
        "def get_news():\n",
        "    file_path = 'aapl_news.csv'\n",
        "    try:\n",
        "        with open(file_path, mode='r', newline='', encoding='utf-8') as file:\n",
        "            csv_reader = csv.DictReader(file)\n",
        "            articles = [row for row in csv_reader]\n",
        "            return articles\n",
        "    except FileNotFoundError:\n",
        "        print(\"News file not found.\")\n",
        "        return None\n",
        "\n",
        "def get_sentiment_and_confidence(text):\n",
        "    \"\"\"Return the sentiment polarity rating (-1, 0, 1) and confidence of the given text.\"\"\"\n",
        "    blob = TextBlob(text)\n",
        "    polarity = blob.sentiment.polarity\n",
        "    confidence = abs(polarity)  # Absolute value of polarity as confidence\n",
        "    if polarity > 0.1:\n",
        "        return 1, confidence\n",
        "    elif polarity < -0.1:\n",
        "        return -1, confidence\n",
        "    else:\n",
        "        return 0, confidence\n",
        "\n",
        "def analyze_sentiments():\n",
        "    articles_data = get_news()\n",
        "    if articles_data:\n",
        "        sentiment_by_date = defaultdict(lambda: {'total_confidence': 0, 'weighted_sentiment_sum': 0})\n",
        "        for article in articles_data:\n",
        "            title = article['title']\n",
        "            date = article['date']  # Assuming there's a 'date' column in your CSV\n",
        "            sentiment, confidence = get_sentiment_and_confidence(title)\n",
        "            sentiment_by_date[date]['weighted_sentiment_sum'] += sentiment * confidence\n",
        "            sentiment_by_date[date]['total_confidence'] += confidence\n",
        "\n",
        "        sentiment_scores = {}\n",
        "        for date, data in sentiment_by_date.items():\n",
        "            if data['total_confidence'] != 0:\n",
        "                sentiment_scores[date] = data['weighted_sentiment_sum'] / data['total_confidence']\n",
        "            else:\n",
        "                sentiment_scores[date] = 0  # Handle case with no data or zero confidence\n",
        "\n",
        "        return sentiment_scores\n",
        "    else:\n",
        "        print(\"No news found\")\n",
        "        return {}\n",
        "\n",
        "overall_sentiment_scores = analyze_sentiments()\n",
        "# Sorting the dates in reverse order before printing\n",
        "for date in sorted(overall_sentiment_scores.keys(), reverse=True):\n",
        "    score = overall_sentiment_scores[date]\n",
        "    print(f\"Sentiment Score for {date}: {score:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmLpmqBDvS5E",
        "outputId": "62110110-594f-4cb5-bc02-bd939e90569d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "News file not found.\n",
            "No news found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_news(file_path):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        articles = df.to_dict(orient='records')\n",
        "        return df, articles\n",
        "    except FileNotFoundError:\n",
        "        print(\"News file not found.\")\n",
        "        return None, None\n",
        "\n",
        "def get_sentiment_and_confidence(text):\n",
        "    blob = TextBlob(text)\n",
        "    polarity = blob.sentiment.polarity\n",
        "    confidence = abs(polarity)\n",
        "    if polarity > 0.1:\n",
        "        return 1, confidence\n",
        "    elif polarity < -0.1:\n",
        "        return -1, confidence\n",
        "    else:\n",
        "        return 0, confidence\n",
        "\n",
        "def analyze_sentiments(articles):\n",
        "    sentiment_by_date = defaultdict(lambda: {'total_confidence': 0, 'weighted_sentiment_sum': 0})\n",
        "    if articles:\n",
        "        for article in articles:\n",
        "            title = article['title']  # Adjust if the column name is different\n",
        "            date = article['date']  # Adjust if the column name is different\n",
        "            sentiment, confidence = get_sentiment_and_confidence(title)\n",
        "            sentiment_by_date[date]['weighted_sentiment_sum'] += sentiment * confidence\n",
        "            sentiment_by_date[date]['total_confidence'] += confidence\n",
        "\n",
        "        sentiment_scores = {}\n",
        "        for date, data in sentiment_by_date.items():\n",
        "            if data['total_confidence'] != 0:\n",
        "                sentiment_scores[date] = data['weighted_sentiment_sum'] / data['total_confidence']\n",
        "            else:\n",
        "                sentiment_scores[date] = 0\n",
        "        return sentiment_scores\n",
        "    else:\n",
        "        print(\"No news found\")\n",
        "        return None\n",
        "\n",
        "# Define file path\n",
        "file_path = '/content/AAPL_news.csv'  # Update with your actual file path\n",
        "\n",
        "# Load data and analyze sentiments\n",
        "news_df, articles_data = get_news(file_path)\n",
        "if articles_data:\n",
        "    sentiment_scores = analyze_sentiments(articles_data)\n",
        "    if sentiment_scores:\n",
        "        # Create DataFrame from sentiment scores\n",
        "        sentiment_df = pd.DataFrame(list(sentiment_scores.items()), columns=['date', 'sentiment_score'])\n",
        "        # Merge sentiment scores with the news dataframe\n",
        "        merged_df = news_df.merge(sentiment_df, on='date', how='left')\n",
        "        # Fill NaN with 0 or an appropriate value for missing sentiment scores\n",
        "        merged_df['sentiment_score'].fillna(0, inplace=True)\n",
        "        # Save updated DataFrame to new CSV\n",
        "        updated_file_path = '/content/AAPL_news_2.csv'\n",
        "        merged_df.to_csv(updated_file_path, index=False)\n",
        "        print(f\"Updated file saved to {updated_file_path}\")\n",
        "    else:\n",
        "        print(\"Failed to analyze sentiments. No updated file created.\")\n",
        "else:\n",
        "    print(\"Failed to retrieve or process the news data.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKNoG16av05J",
        "outputId": "97ac1e15-de27-4ab2-fbde-8167c519bfba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "News file not found.\n",
            "Failed to retrieve or process the news data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iOE8CHJMWLVk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}